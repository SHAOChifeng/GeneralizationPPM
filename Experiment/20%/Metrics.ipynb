{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "\n",
    "import copy\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def import_log(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    return(df.values.tolist())\n",
    "\n",
    "def remove_nan(lists):\n",
    "    newlists = []\n",
    "    for tr in lists:\n",
    "        newlists.append([int(x) for x in tr if str(x) != 'nan'])\n",
    "    return(newlists)\n",
    "\n",
    "\n",
    "\n",
    "def delete_variant(log, variant):\n",
    "    return([trace for trace in log if trace != variant])\n",
    "\n",
    "def get_variants_list(lst): #get all of the variants in a list, return as list\n",
    "    st = set(tuple(i) for i in lst) #convert list into set of tuples\n",
    "    lst2 = list(st) #convert set of tuples into lsit of tuples\n",
    "    return [list(e) for e in lst2] \n",
    "\n",
    "def count_variant(log, variant): #count how many times a variant comes up in list\n",
    "    c = 0\n",
    "    for trace in log:\n",
    "        if trace == variant:\n",
    "            c += 1\n",
    "    return(c)\n",
    "\n",
    "def compare_variants(var1, var2): #compare two logs, what comes up in the other \n",
    "    s1 = set(tuple(i) for i in var1)\n",
    "    s2 = set(tuple(i) for i in var2)\n",
    "    \n",
    "   # print(\"Missing values in second list:\", (s1.difference(s2))) \n",
    "   # print(\"Additional values in second list:\", (s2.difference(s1))) \n",
    "    \n",
    "    return([list(e) for e in list(s1.difference(s2))],[list(e) for e in list(s2.difference(s1))])\n",
    "\n",
    "def demap_trace(t, mapping): #unmap trace, from number encoding to activity label\n",
    "    map = {v: k for k, v in mapping.items()}\n",
    "    return [map[a] for a in t]\n",
    "\n",
    "\n",
    "\n",
    "def apply_integer_map(log, map):\n",
    "    return [[map[a['concept:name']] for a in t] for t in log]\n",
    "\n",
    "#fucntion gets the counts of all of the variants \n",
    "\n",
    "def get_counts(log, variants):\n",
    "    counts = []\n",
    "    for var in variants:\n",
    "        counts.append(count_variant(log, var))\n",
    "    return counts\n",
    "\n",
    "\n",
    "def get_fitness(occ_each_trvar_sim, occ_each_trvar_tr):\n",
    "    arr = [min(occ_each_trvar_sim[i], occ_each_trvar_tr[i])/sum(occ_each_trvar_tr) for i in range(0, len(occ_each_trvar_sim))]\n",
    "    return sum(arr)\n",
    "\n",
    "def get_precision(occ_each_simvar_sim, occ_each_simvar_trte):\n",
    "    arr = [min(occ_each_simvar_sim[i], occ_each_simvar_trte[i])/sum(occ_each_simvar_sim) for i in range(0, len(occ_each_simvar_sim))]\n",
    "    return sum(arr)\n",
    "\n",
    "def get_generalization(occ_each_tevar_sim, occ_each_tevar_te):\n",
    "    arr = [min(occ_each_tevar_sim[i], occ_each_tevar_te[i])/sum(occ_each_tevar_te) for i in range(0, len(occ_each_tevar_sim))]\n",
    "    return sum(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(modelname):\n",
    "    varname = 'Variants/variants_' + modelname+'.csv'\n",
    "    variants = remove_nan(import_log(varname))\n",
    "    trtename = 'Train+Test_sets/Log_' + modelname +'.csv'\n",
    "    traintestlog = remove_nan(import_log(trtename ))\n",
    "    \n",
    "    overall_counts = get_counts(traintestlog, variants)\n",
    "    \n",
    "    fitness_arr = []\n",
    "    precision_arr = []\n",
    "    generalization_arr = []\n",
    "\n",
    "    trainname = \"Train_sets/log_\" + modelname +'.csv'\n",
    "    trainlog = remove_nan(import_log(trainname))\n",
    "\n",
    "    SimLogName = 'Sim_sets/Log_'+ modelname + '.csv'\n",
    "    simlog = remove_nan(import_log(SimLogName))\n",
    "\n",
    "    TestLogName = \"Test_sets/log_\" + modelname +'.csv'\n",
    "    testlog = remove_nan(import_log(TestLogName))\n",
    "\n",
    "    #needed to calculate metrics\n",
    "    trvar = get_variants_list(trainlog)\n",
    "    simvar = get_variants_list(simlog)\n",
    "    tevar = get_variants_list(testlog) #this is unique tot eh one-hot seting, needs to be altered when using bigger test set\n",
    "\n",
    "    #get counts for the simulated log\n",
    "    occ_each_trvar_sim = get_counts(simlog, trvar)\n",
    "    occ_each_tevar_sim = get_counts(simlog, tevar)\n",
    "    occ_each_simvar_sim = get_counts(simlog, simvar)\n",
    "\n",
    "    #get counts for the train log\n",
    "    occ_each_trvar_tr = get_counts(trainlog, trvar)\n",
    "\n",
    "    #get counts for the test log\n",
    "    occ_each_tevar_te = get_counts(testlog, tevar)\n",
    "\n",
    "    #get counts for the train test log\n",
    "    occ_each_simvar_trte = get_counts(traintestlog, simvar)\n",
    "\n",
    "    fit = get_fitness(occ_each_trvar_sim, occ_each_trvar_tr)\n",
    "    prec = get_precision(occ_each_simvar_sim, occ_each_simvar_trte)\n",
    "    gen = get_generalization(occ_each_tevar_sim, occ_each_tevar_te)\n",
    "\n",
    "    return(overall_counts, fit, prec, gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, fit, prec, gen = get_metrics('Model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9318323952470295 0.8885000000000004 0.7157107231920198\n"
     ]
    }
   ],
   "source": [
    "print(fit, prec, gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, fit, prec, gen = get_metrics('Model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9380474934036944 0.9249166666666665 0.8756435643564359\n"
     ]
    }
   ],
   "source": [
    "print(fit, prec, gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, fit, prec, gen = get_metrics('Model3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9402122517600087 0.9265833333333334 0.8743455497382197\n"
     ]
    }
   ],
   "source": [
    "print(fit, prec, gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, fit, prec, gen = get_metrics('Model4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9310381244059563 0.8776666666666667 0.6779928881864876\n"
     ]
    }
   ],
   "source": [
    "print(fit, prec, gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, fit, prec, gen = get_metrics('Model5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.929255097794424 0.8438333333333334 0.49999999999999994\n"
     ]
    }
   ],
   "source": [
    "print(fit, prec, gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, fit, prec, gen = get_metrics('Model6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9233345738742088 0.9210833333333313 0.9017571884984026\n"
     ]
    }
   ],
   "source": [
    "print(fit, prec, gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, fit, prec, gen = get_metrics('MoreComplex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8378081714435226 0.8233484848484979 0.7269029633933762\n"
     ]
    }
   ],
   "source": [
    "print(fit, prec, gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
